{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Pre-training BERT from scratch with cloud TPU",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/algharak/bert_colab_TPU/blob/master/Copy_of_Pre_training_BERT_from_scratch_with_cloud_TPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2XB_l-Hgzq_",
        "colab_type": "text"
      },
      "source": [
        "# Pre-training BERT from scratch with cloud TPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZPgpRl5g2e2",
        "colab_type": "text"
      },
      "source": [
        "In this experiment, we will be pre-training a state-of-the-art Natural Language Understanding model [BERT](https://arxiv.org/abs/1810.04805.) on arbitrary text data using Google Cloud infrastructure.\n",
        "\n",
        "This guide covers all stages of the procedure, including:\n",
        "\n",
        "1. Setting up the training environment\n",
        "2. Downloading raw text data\n",
        "3. Preprocessing text data\n",
        "4. Learning a new vocabulary\n",
        "5. Creating sharded pre-training data\n",
        "6. Setting up GCS storage for data and model\n",
        "7. Training the model on a cloud TPU\n",
        "\n",
        "For persistent storage of training data and model, you will require a Google Cloud Storage bucket. \n",
        "Please follow the [Google Cloud TPU quickstart](https://cloud.google.com/tpu/docs/quickstart) to create a GCP account and GCS bucket. New Google Cloud users have [$300 free credit](https://cloud.google.com/free/) to get started with any GCP product. \n",
        "\n",
        "Steps 1-5 of this tutorial can be run without a GCS bucket for demonstration purposes. In that case, however, you will not be able to train the model.\n",
        "\n",
        "**Note** \n",
        "The only parameter you *really have to set* is BUCKET_NAME in steps 5 and 6. Everything else has default values which should work for most use-cases.\n",
        "\n",
        "**Note** \n",
        "Pre-training a BERT-Base model on a TPUv2 will take about 54 hours. Google Colab is not designed for executing such long-running jobs and will interrupt the training process every 8 hours or so. For uninterrupted training, consider using a preemptible TPUv2 instance. \n",
        "\n",
        "That said, at the time of writing (09.05.2019), with a Colab TPU, pre-training a BERT model from scratch can be achieved at a negligible cost of storing the said model and data in GCS  (~1 USD).\n",
        "\n",
        "Now, let's get to business."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODimOhBR05yR",
        "colab_type": "text"
      },
      "source": [
        "MIT License\n",
        "\n",
        "Copyright (c) [2019] [Antyukhov Denis Olegovich]\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fjad5jsr9YaM",
        "colab_type": "text"
      },
      "source": [
        "## Step 1: setting up training environment\n",
        "First and foremost, we get the packages required to train the model. \n",
        "The Jupyter environment allows executing bash commands directly from the notebook by using an exclamation mark ‘!’. I will be exploiting this approach to make use of several other bash commands throughout the experiment.\n",
        "\n",
        "Now, let’s import the packages and authorize ourselves in Google Cloud."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S4CiOh3RzFW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "837c86fc-3cc0-4b33-c186-29f6489830cf"
      },
      "source": [
        "!pip install sentencepiece\n",
        "!git clone https://github.com/google-research/bert\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import nltk\n",
        "import random\n",
        "import logging\n",
        "import tensorflow as tf\n",
        "import sentencepiece as spm\n",
        "\n",
        "from glob import glob\n",
        "from google.colab import auth, drive\n",
        "from tensorflow.keras.utils import Progbar\n",
        "\n",
        "sys.path.append(\"bert\")\n",
        "\n",
        "from bert import modeling, optimization, tokenization\n",
        "from bert.run_pretraining import input_fn_builder, model_fn_builder\n",
        "\n",
        "auth.authenticate_user()\n",
        "  \n",
        "# configure logging\n",
        "log = logging.getLogger('tensorflow')\n",
        "log.setLevel(logging.INFO)\n",
        "\n",
        "# create formatter and add it to the handlers\n",
        "formatter = logging.Formatter('%(asctime)s :  %(message)s')\n",
        "sh = logging.StreamHandler()\n",
        "sh.setLevel(logging.INFO)\n",
        "sh.setFormatter(formatter)\n",
        "log.handlers = [sh]\n",
        "\n",
        "if 'COLAB_TPU_ADDR' in os.environ:\n",
        "  log.info(\"Using TPU runtime\")\n",
        "  USE_TPU = True\n",
        "  TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "\n",
        "  with tf.Session(TPU_ADDRESS) as session:\n",
        "    log.info('TPU address is ' + TPU_ADDRESS)\n",
        "    # Upload credentials to TPU.\n",
        "    with open('/content/adc.json', 'r') as f:\n",
        "      auth_info = json.load(f)\n",
        "    tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "    \n",
        "else:\n",
        "  log.warning('Not connected to TPU runtime')\n",
        "  USE_TPU = False"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.83)\n",
            "fatal: destination path 'bert' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-10-16 04:47:56,572 :  Using TPU runtime\n",
            "2019-10-16 04:47:56,582 :  TPU address is grpc://10.1.178.146:8470\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSEeapmLJKWO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "c8cfa50c-c2a2-43a3-f886-429dfedcb795"
      },
      "source": [
        "!head -n 10 adc.json\n",
        "\n",
        "\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"client_id\": \"32555940559.apps.googleusercontent.com\",\n",
            "  \"client_secret\": \"ZmssLNjJy2998hD4CTg2ejr2\",\n",
            "  \"id_token\": {\n",
            "    \"at_hash\": \"B4qN32SmbmNL2tB9DjL2ww\",\n",
            "    \"aud\": \"32555940559.apps.googleusercontent.com\",\n",
            "    \"azp\": \"32555940559.apps.googleusercontent.com\",\n",
            "    \"email\": \"al@cogneefy.com\",\n",
            "    \"email_verified\": true,\n",
            "    \"exp\": 1571192266,\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGVXMoC-aMy1",
        "colab_type": "text"
      },
      "source": [
        "## Step 2: getting the data\n",
        "\n",
        "We begin with obtaining a corpus of raw text data. For this experiment, we will be using the [OpenSubtitles](http://www.opensubtitles.org/) dataset, which is available for 65 languages [here](http://opus.nlpl.eu/OpenSubtitles-v2016.php). \n",
        "\n",
        "Unlike more common text datasets (like Wikipedia) it does not require any complex pre-processing. It also comes pre-formatted with one sentence per line.\n",
        "\n",
        "Feel free to use the dataset for your language instead by changing the language code (en) below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FotFkkshbdvK",
        "colab_type": "code",
        "outputId": "2bf64d61-68be-4854-cc0e-46d8f10f1d32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "AVAILABLE =  {'af','ar','bg','bn','br','bs','ca','cs',\n",
        "              'da','de','el','en','eo','es','et','eu',\n",
        "              'fa','fi','fr','gl','he','hi','hr','hu',\n",
        "              'hy','id','is','it','ja','ka','kk','ko',\n",
        "              'lt','lv','mk','ml','ms','nl','no','pl',\n",
        "              'pt','pt_br','ro','ru','si','sk','sl','sq',\n",
        "              'sr','sv','ta','te','th','tl','tr','uk',\n",
        "              'ur','vi','ze_en','ze_zh','zh','zh_cn',\n",
        "              'zh_en','zh_tw','zh_zh'}\n",
        "\n",
        "LANG_CODE = \"en\" #@param {type:\"string\"}\n",
        "\n",
        "assert LANG_CODE in AVAILABLE, \"Invalid language code selected\"\n",
        "\n",
        "!wget http://opus.nlpl.eu/download.php?f=OpenSubtitles/v2016/mono/OpenSubtitles.raw.'$LANG_CODE'.gz -O dataset.txt.gz\n",
        "!gzip -d dataset.txt.gz\n",
        "!tail dataset.txt"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-16 04:52:15--  http://opus.nlpl.eu/download.php?f=OpenSubtitles/v2016/mono/OpenSubtitles.raw.en.gz\n",
            "Resolving opus.nlpl.eu (opus.nlpl.eu)... 193.166.25.9\n",
            "Connecting to opus.nlpl.eu (opus.nlpl.eu)|193.166.25.9|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://object.pouta.csc.fi/OPUS-OpenSubtitles/v2016/mono/en.txt.gz [following]\n",
            "--2019-10-16 04:52:15--  https://object.pouta.csc.fi/OPUS-OpenSubtitles/v2016/mono/en.txt.gz\n",
            "Resolving object.pouta.csc.fi (object.pouta.csc.fi)... 86.50.254.18\n",
            "Connecting to object.pouta.csc.fi (object.pouta.csc.fi)|86.50.254.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2906709304 (2.7G) [application/gzip]\n",
            "Saving to: ‘dataset.txt.gz’\n",
            "\n",
            "dataset.txt.gz      100%[===================>]   2.71G  21.0MB/s    in 2m 12s  \n",
            "\n",
            "2019-10-16 04:54:28 (21.0 MB/s) - ‘dataset.txt.gz’ saved [2906709304/2906709304]\n",
            "\n",
            "gzip: dataset.txt already exists; do you wish to overwrite (y or n)? n\n",
            "\tnot overwritten\n",
            "Paige, come on, okay?\n",
            "Letting you go, biggest mistake of my life.\n",
            "I lost you... and now you're... now you're married to a king.\n",
            "What am I supposed to do with that?\n",
            "You're not supposed to do anything with it.\n",
            "You're living a little girl's dream, Paige.\n",
            "It's not your dream.\n",
            "You never wanted any of this.\n",
            "You wanted to be a doctor, and now you've given it up for some fantasy.\n",
            "- It"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nb5TPsPOppn0",
        "colab_type": "text"
      },
      "source": [
        "For demonstration purposes, we will only use a small fraction of the whole corpus for this experiment. \n",
        "\n",
        "When training the real model, make sure to uncheck the DEMO_MODE checkbox to use a 100x larger dataset.\n",
        "\n",
        "Rest assured, 100M lines are perfectly sufficient to train a reasonably good BERT-base model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkxbVDslIeFk",
        "colab_type": "text"
      },
      "source": [
        "I am saving at this checkpoint since things seems to have been working\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDR5Z1MDgB1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEMO_MODE = True #@param {type:\"boolean\"}\n",
        "\n",
        "if DEMO_MODE:\n",
        "  CORPUS_SIZE = 1000000\n",
        "else:\n",
        "  CORPUS_SIZE = 9999989 #@param {type: \"integer\"}\n",
        "  \n",
        "!(head -n $CORPUS_SIZE dataset.txt) > subdataset.txt\n",
        "!mv subdataset.txt dataset.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n43zSM6kJ0Hp",
        "colab_type": "code",
        "outputId": "e9635aa9-dc10-43c1-9b27-0d57274709c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "%ls -al\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 2894120\n",
            "drwxr-xr-x 1 root root       4096 Oct 16 04:55 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x 1 root root       4096 Oct 16 01:03 \u001b[01;34m..\u001b[0m/\n",
            "-rw-r--r-- 1 root root       2654 Oct 16 01:17 adc.json\n",
            "drwxr-xr-x 4 root root       4096 Oct 16 01:17 \u001b[01;34mbert\u001b[0m/\n",
            "drwxr-xr-x 2 root root       4096 Oct 16 02:18 \u001b[01;34mbert_model\u001b[0m/\n",
            "drwxr-xr-x 1 root root       4096 Oct 16 01:17 \u001b[01;34m.config\u001b[0m/\n",
            "-rw-r--r-- 1 root root   28543866 Oct 16 04:55 dataset.txt\n",
            "-rw-r--r-- 1 root root 2906709304 Nov 17  2018 dataset.txt.gz\n",
            "drwxr-xr-x 2 root root       4096 Oct 16 02:04 \u001b[01;34mpretraining_data\u001b[0m/\n",
            "-rw-r--r-- 1 root root   26648696 Oct 16 01:51 proc_dataset.txt\n",
            "drwxr-xr-x 1 root root       4096 Aug 27 16:17 \u001b[01;34msample_data\u001b[0m/\n",
            "drwxr-xr-x 2 root root       4096 Oct 16 01:59 \u001b[01;34mshards\u001b[0m/\n",
            "-rw-r--r-- 1 root root     788084 Oct 16 01:52 tokenizer.model\n",
            "-rw-r--r-- 1 root root     578702 Oct 16 01:52 tokenizer.vocab\n",
            "-rw-r--r-- 1 root root     246458 Oct 16 01:59 vocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X58Z7OSaKRS-",
        "colab_type": "text"
      },
      "source": [
        "I stopped here and will be updating the github"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRQd4-v0nQqH",
        "colab_type": "text"
      },
      "source": [
        "## Step 3: preprocessing text\n",
        "\n",
        "The raw text data we have downloaded contains punсtuation, uppercase letters and non-UTF symbols which we will remove before proceeding. During inference, we will apply the same normalization procedure to new data.\n",
        "\n",
        "If your use-case requires different preprocessing (e.g. if uppercase letters or punctuation are expected during inference), feel free to modify the function below to accomodate for your needs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCi2oSdInRkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "regex_tokenizer = nltk.RegexpTokenizer(\"\\w+\")\n",
        "\n",
        "def normalize_text(text):\n",
        "  # lowercase text\n",
        "  text = str(text).lower()\n",
        "  # remove non-UTF\n",
        "  text = text.encode(\"utf-8\", \"ignore\").decode()\n",
        "  # remove punktuation symbols\n",
        "  text = \" \".join(regex_tokenizer.tokenize(text))\n",
        "  return text\n",
        "\n",
        "def count_lines(filename):\n",
        "  count = 0\n",
        "  with open(filename) as fi:\n",
        "    for line in fi:\n",
        "      count += 1\n",
        "  return count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYtwtDnesaQQ",
        "colab_type": "text"
      },
      "source": [
        "Check how that works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gngtEZWqVhY",
        "colab_type": "code",
        "outputId": "33d0bb12-845c-4a23-9ead-9adb0fe90b8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "normalize_text('Thanks to the advance, they have succeeded in getting over their adversaries.')"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'thanks to the advance they have succeeded in getting over their adversaries'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY-Kvnx6sUFS",
        "colab_type": "text"
      },
      "source": [
        "Apply normalization to the whole dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myjxQe5awo1v",
        "colab_type": "code",
        "outputId": "c3c0a74f-06e8-4111-b4a8-6236e919dfdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "RAW_DATA_FPATH = \"dataset.txt\" #@param {type: \"string\"}\n",
        "PRC_DATA_FPATH = \"proc_dataset.txt\" #@param {type: \"string\"}\n",
        "\n",
        "# apply normalization to the dataset\n",
        "# this will take a minute or two\n",
        "\n",
        "total_lines = count_lines(RAW_DATA_FPATH)\n",
        "bar = Progbar(total_lines)\n",
        "\n",
        "with open(RAW_DATA_FPATH,encoding=\"utf-8\") as fi:\n",
        "  with open(PRC_DATA_FPATH, \"w\",encoding=\"utf-8\") as fo:\n",
        "    for l in fi:\n",
        "      fo.write(normalize_text(l)+\"\\n\")\n",
        "      bar.add(1)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000000/1000000 [==============================] - 6s 6us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3A64RZjwo9k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVO9EnUwrluQ",
        "colab_type": "text"
      },
      "source": [
        "## Step 4: building the vocabulary\n",
        "\n",
        "For the next step, we will learn a new vocabulary that we will use to represent our dataset. \n",
        "\n",
        "The BERT paper uses a WordPiece tokenizer, which is not available in opensource. Instead, we will be using SentencePiece tokenizer in unigram mode. While it is not directly compatible with BERT, with a small hack we can make it work.\n",
        "\n",
        "SentencePiece requires quite a lot of RAM, so running it on the full dataset in Colab will crash the kernel. To avoid this, we will randomly subsample a fraction of the dataset for building the vocabulary. Another option would be to use a machine with more RAM for this step - that decision is up to you.\n",
        "\n",
        "Also, SentencePiece adds BOS and EOS control symbols to the vocabulary by default. We disable them explicitly by setting their indices to -1.\n",
        "\n",
        "The typical values for VOC_SIZE are somewhere in between 32000 and 128000. We reserve NUM_PLACEHOLDERS tokens in case one wants to update the vocabulary and fine-tune the model after the pre-training phase is finished."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18nn6eW_s-fV",
        "colab_type": "code",
        "outputId": "ff0d5a2a-6018-4850-9bc3-edaf86a44708",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "MODEL_PREFIX = \"tokenizer\" #@param {type: \"string\"}\n",
        "VOC_SIZE = 32000 #@param {type:\"integer\"}\n",
        "SUBSAMPLE_SIZE = 12800000 #@param {type:\"integer\"}\n",
        "NUM_PLACEHOLDERS = 256 #@param {type:\"integer\"}\n",
        "\n",
        "SPM_COMMAND = ('--input={} --model_prefix={} '\n",
        "               '--vocab_size={} --input_sentence_size={} '\n",
        "               '--shuffle_input_sentence=true ' \n",
        "               '--bos_id=-1 --eos_id=-1').format(\n",
        "               PRC_DATA_FPATH, MODEL_PREFIX, \n",
        "               VOC_SIZE - NUM_PLACEHOLDERS, SUBSAMPLE_SIZE)\n",
        "\n",
        "spm.SentencePieceTrainer.Train(SPM_COMMAND)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAowCoH2u1iZ",
        "colab_type": "text"
      },
      "source": [
        "Now let's see how we can make SentencePiece tokenizer work for the BERT model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OLaw7kPW3he",
        "colab_type": "text"
      },
      "source": [
        "Below is a sentence tokenized using the WordPiece vocabulary from a pretrained English [BERT-base](https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip) model from the official [repo](https://github.com/google-research/bert). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwHAp_Gh5OPK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testcase = \"Colorless geothermal substations are generating furiously\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyEGAVl_5YRD",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        ">>> wordpiece.tokenize(\"Colorless geothermal substations are generating furiously\")\n",
        "\n",
        "['color',\n",
        " '##less',\n",
        " 'geo',\n",
        " '##thermal',\n",
        " 'sub',\n",
        " '##station',\n",
        " '##s',\n",
        " 'are',\n",
        " 'generating',\n",
        " 'furiously']\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNiLdWXTh9cj",
        "colab_type": "text"
      },
      "source": [
        "As we can see, the WordPiece tokenizer prepends the subwords which occur in the middle of words with '##'. The subwords occurring at the beginning of words are unchanged. If the subword occurs both in the beginning and in the middle of words, both versions (with and without '##') are added to the vocabulary.\n",
        "\n",
        "Now let's have a look at the vocabulary that the SentencePiece tokenizer has learned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8_ebLxqTnWu",
        "colab_type": "code",
        "outputId": "771dd4f7-ab4c-47bf-be98-4ee140cf4d83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json    dataset.txt       proc_dataset.txt\ttokenizer.model\n",
            "bert\t    dataset.txt.gz    sample_data\ttokenizer.vocab\n",
            "bert_model  pretraining_data  shards\t\tvocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYlBqiv5UD-j",
        "colab_type": "text"
      },
      "source": [
        "SentencePiece has created two files: tokenizer.model and tokenizer.vocab. Let's have a look at the learned vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDJ9QmNMUEQf",
        "colab_type": "code",
        "outputId": "f99fe5f6-725e-45e3-bf02-52c1b1343e73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!head -n 100 tokenizer.vocab"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<unk>\t0\n",
            "▁you\t-3.2342\n",
            "▁i\t-3.2821\n",
            "▁the\t-3.56375\n",
            "▁s\t-3.84955\n",
            "▁to\t-3.87601\n",
            "▁a\t-3.9102\n",
            "▁it\t-3.97593\n",
            "▁t\t-4.25729\n",
            "▁and\t-4.32686\n",
            "▁that\t-4.33991\n",
            "▁of\t-4.57503\n",
            "▁what\t-4.59504\n",
            "▁is\t-4.67144\n",
            "▁me\t-4.7115\n",
            "▁in\t-4.71265\n",
            "▁we\t-4.7231\n",
            "▁he\t-4.88446\n",
            "▁this\t-4.89466\n",
            "▁no\t-4.98519\n",
            "▁on\t-4.99226\n",
            "▁my\t-4.99616\n",
            "▁m\t-5.02169\n",
            "▁your\t-5.02715\n",
            "▁for\t-5.05648\n",
            "▁have\t-5.06695\n",
            "▁don\t-5.09057\n",
            "▁do\t-5.12828\n",
            "▁\t-5.12998\n",
            "▁re\t-5.1371\n",
            "▁can\t-5.20534\n",
            "▁was\t-5.20891\n",
            "▁know\t-5.22494\n",
            "▁be\t-5.23557\n",
            "▁are\t-5.25247\n",
            "▁not\t-5.26685\n",
            "▁all\t-5.29439\n",
            "▁with\t-5.31925\n",
            "▁but\t-5.37188\n",
            "▁so\t-5.42124\n",
            "▁get\t-5.43031\n",
            "▁here\t-5.43446\n",
            "▁just\t-5.43719\n",
            "▁ll\t-5.49322\n",
            "▁like\t-5.5182\n",
            "▁they\t-5.5196\n",
            "▁there\t-5.52012\n",
            "▁up\t-5.55201\n",
            "▁go\t-5.55369\n",
            "▁she\t-5.5887\n",
            "▁right\t-5.61613\n",
            "▁out\t-5.64626\n",
            "▁oh\t-5.68517\n",
            "s\t-5.71583\n",
            "▁come\t-5.73109\n",
            "▁if\t-5.73944\n",
            "▁him\t-5.74635\n",
            "▁one\t-5.75141\n",
            "▁about\t-5.75416\n",
            "▁got\t-5.77074\n",
            "▁at\t-5.78535\n",
            "▁now\t-5.8265\n",
            "▁yeah\t-5.84144\n",
            "▁how\t-5.84948\n",
            "▁her\t-5.87603\n",
            "▁well\t-5.94933\n",
            "▁let\t-5.95131\n",
            "▁good\t-5.98986\n",
            "▁want\t-6.01295\n",
            "▁ve\t-6.02348\n",
            "▁think\t-6.04507\n",
            "▁who\t-6.06409\n",
            "▁did\t-6.09598\n",
            "▁see\t-6.10352\n",
            "▁why\t-6.11416\n",
            "▁will\t-6.12599\n",
            "▁gonna\t-6.17628\n",
            "▁from\t-6.17938\n",
            "▁look\t-6.19767\n",
            "▁as\t-6.20588\n",
            "▁yes\t-6.21377\n",
            "▁back\t-6.22989\n",
            "▁d\t-6.23892\n",
            "▁his\t-6.24827\n",
            "n\t-6.25315\n",
            "▁man\t-6.25455\n",
            "▁when\t-6.26481\n",
            "▁okay\t-6.27249\n",
            "▁time\t-6.27638\n",
            "▁could\t-6.28472\n",
            "▁take\t-6.30417\n",
            "▁hey\t-6.31565\n",
            "▁say\t-6.35372\n",
            "▁had\t-6.37539\n",
            "▁an\t-6.37643\n",
            "▁us\t-6.38685\n",
            "▁or\t-6.38714\n",
            "▁were\t-6.38932\n",
            "▁some\t-6.39201\n",
            "▁where\t-6.39465\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBsURk_h5jw4",
        "colab_type": "code",
        "outputId": "51bc542c-d539-4839-a956-fe68a628f7b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def read_sentencepiece_vocab(filepath):\n",
        "  voc = []\n",
        "  with open(filepath, encoding='utf-8') as fi:\n",
        "    for line in fi:\n",
        "      voc.append(line.split(\"\\t\")[0])\n",
        "  # skip the first <unk> token\n",
        "  voc = voc[1:]\n",
        "  return voc\n",
        "\n",
        "snt_vocab = read_sentencepiece_vocab(\"{}.vocab\".format(MODEL_PREFIX))\n",
        "print(\"Learnt vocab size: {}\".format(len(snt_vocab)))\n",
        "print(\"Sample tokens: {}\".format(random.sample(snt_vocab, 10)))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learnt vocab size: 31743\n",
            "Sample tokens: ['▁tebas', '▁airplane', 'ph', '▁roche', '▁skirts', '▁harder', '▁lud', '▁hopes', '▁yourself', '▁geisha']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJPtxrtz5470",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YjqHVRpmlKq",
        "colab_type": "text"
      },
      "source": [
        "As we may observe, SentencePiece does quite the opposite to WordPiece. From the [documentation](https://github.com/google/sentencepiece/blob/master/README.md):\n",
        "\n",
        "\n",
        "SentencePiece first escapes the whitespace with a meta-symbol \"▁\" (U+2581) as follows:\n",
        "\n",
        "`Hello▁World`.\n",
        "\n",
        "Then, this text is segmented into small pieces, for example:\n",
        "\n",
        "`[Hello] [▁Wor] [ld] [.]`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OD-28l_0p0PQ",
        "colab_type": "text"
      },
      "source": [
        "Subwords which occur after whitespace (which are also those that most words begin with) are prepended with '▁', while others are unchanged. This excludes subwords which only occur at the beginning of sentences and nowhere else. These cases should be quite rare, however. \n",
        "\n",
        "So, in order to obtain a vocabulary analogous to WordPiece, we need to perform a simple conversion, removing \"▁\" from the tokens that contain it and adding \"##\"  to the ones that don't."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QJGFjzOMbfN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_sentencepiece_token(token):\n",
        "    if token.startswith(\"▁\"):\n",
        "        return token[1:]\n",
        "    else:\n",
        "        return \"##\" + token"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64dcVgD98S28",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_vocab = list(map(parse_sentencepiece_token, snt_vocab))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mL9ZR3RN9IMA",
        "colab_type": "text"
      },
      "source": [
        "We also add some special control symbols which are required by the BERT architecture. By convention, we put those at the beginning of the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdTlXDPL8cHE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ctrl_symbols = [\"[PAD]\",\"[UNK]\",\"[CLS]\",\"[SEP]\",\"[MASK]\"]\n",
        "bert_vocab = ctrl_symbols + bert_vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ry1jvEr9EIdd",
        "colab_type": "text"
      },
      "source": [
        "We also append some placeholder tokens to the vocabulary. Those are useful if one wishes to update the pre-trained model with new, task-specific tokens. \n",
        "\n",
        "In that case, the placeholder tokens are replaced with new real ones, the pre-training data is re-generated, and the model is fine-tuned on new data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLYSTil4E0Dm",
        "colab_type": "code",
        "outputId": "62d85983-ec65-4d26-e392-b2d5efad974a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bert_vocab += [\"[UNUSED_{}]\".format(i) for i in range(VOC_SIZE - len(bert_vocab))]\n",
        "print(len(bert_vocab))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJKk_7JI-MtW",
        "colab_type": "text"
      },
      "source": [
        "Finally, we write the obtained vocabulary to file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8G1jg0cj9Duf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VOC_FNAME = \"vocab.txt\" #@param {type:\"string\"}\n",
        "\n",
        "with open(VOC_FNAME, \"w\") as fo:\n",
        "  for token in bert_vocab:\n",
        "    fo.write(token+\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MqXZnc3FCuY",
        "colab_type": "text"
      },
      "source": [
        "Now let's see how the new vocabulary works in practice:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsSOnEnC-jG1",
        "colab_type": "code",
        "outputId": "f4788eac-14cd-46fe-dd62-96de041219f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "bert_tokenizer = tokenization.FullTokenizer(VOC_FNAME)\n",
        "bert_tokenizer.tokenize(testcase)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['color',\n",
              " '##less',\n",
              " 'geo',\n",
              " '##ther',\n",
              " '##mal',\n",
              " 'subs',\n",
              " '##tation',\n",
              " '##s',\n",
              " 'are',\n",
              " 'generat',\n",
              " '##ing',\n",
              " 'furious',\n",
              " '##ly']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RN8xDNfF0Q2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DauD8ndhEA-z",
        "colab_type": "text"
      },
      "source": [
        "Looking good!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwFtStCo__QX",
        "colab_type": "text"
      },
      "source": [
        "## Step 5: generating pre-training data\n",
        "\n",
        "With the vocabulary at hand, we are ready to generate pre-training data for the BERT model. Since our dataset might be quite large, we will split it into shards:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyN1nI04-uKV",
        "colab_type": "code",
        "outputId": "e583a51a-47f1-49e8-ee46-4f1c34c0ff54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!mkdir ./shards\n",
        "!split -a 4 -l 256000 -d $PRC_DATA_FPATH ./shards/shard_\n",
        "!ls ./shards/"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘./shards’: File exists\n",
            "shard_0000  shard_0001\tshard_0002  shard_0003\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-FSq3zNFvLs",
        "colab_type": "text"
      },
      "source": [
        "Before we start generating, we need to set some model-specific parameters.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnZcD0yIBGPd",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "MAX_SEQ_LENGTH = 128 #@param {type:\"integer\"}\n",
        "MASKED_LM_PROB = 0.15 #@param\n",
        "MAX_PREDICTIONS = 20 #@param {type:\"integer\"}\n",
        "DO_LOWER_CASE = True #@param {type:\"boolean\"}\n",
        "PROCESSES = 2 #@param {type:\"integer\"}\n",
        "PRETRAINING_DIR = \"pretraining_data\" #@param {type:\"string\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-MibOBkFam2",
        "colab_type": "text"
      },
      "source": [
        "Now, for each shard we need to call *create_pretraining_data.py* script. To that end, we will employ the  *xargs* command. \n",
        "\n",
        "Running this might take quite some time depending on the size of your dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbZjIeVP0T36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "XARGS_CMD = (\"ls ./shards/ | \"\n",
        "             \"xargs -n 1 -P {} -I{} \"\n",
        "             \"python3 bert/create_pretraining_data.py \"\n",
        "             \"--input_file=./shards/{} \"\n",
        "             \"--output_file={}/{}.tfrecord \"\n",
        "             \"--vocab_file={} \"\n",
        "             \"--do_lower_case={} \"\n",
        "             \"--max_predictions_per_seq={} \"\n",
        "             \"--max_seq_length={} \"\n",
        "             \"--masked_lm_prob={} \"\n",
        "             \"--random_seed=34 \"\n",
        "             \"--dupe_factor=5\")\n",
        "\n",
        "XARGS_CMD = XARGS_CMD.format(PROCESSES, '{}', '{}', PRETRAINING_DIR, '{}', \n",
        "                             VOC_FNAME, DO_LOWER_CASE, \n",
        "                             MAX_PREDICTIONS, MAX_SEQ_LENGTH, MASKED_LM_PROB)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fyo9_LcQ0pla",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5XzaY8xCdiV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.gfile.MkDir(PRETRAINING_DIR)\n",
        "!$XARGS_CMD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKnW_hVxPoP6",
        "colab_type": "text"
      },
      "source": [
        "## Step 6: setting up persistent storage\n",
        "\n",
        "To preserve our hard-earned assets, we will persist them to Google Cloud Storage. Provided that you have created the GCS bucket, this should be simple.\n",
        "\n",
        "We will create two directories in GCS, one for the data and one for the model.\n",
        "In the model directory, we will put the model vocabulary and configuration file.\n",
        "\n",
        "**Configure your BUCKET_NAME variable here before proceeding, otherwise the model and data will not be saved.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDtrt68QQIHs",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "BUCKET_NAME = \"evalbert_bucket\" #@param {type:\"string\"}\n",
        "MODEL_DIR = \"bert_model\" #@param {type:\"string\"}\n",
        "tf.gfile.MkDir(MODEL_DIR)\n",
        "\n",
        "if not BUCKET_NAME:\n",
        "  log.warning(\"WARNING: BUCKET_NAME is not set. \"\n",
        "              \"You will not be able to train the model.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPfgFlmiF0ss",
        "colab_type": "text"
      },
      "source": [
        "Note: I added the following to accomodate authentication.  For thie project I am using\n",
        "BUCKET_NAME = evalbert_bucket\n",
        "Project id:  bert-255419 name:evalbert\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4i1izZz6-oAW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "881ca060-b4fe-4740-908e-81356ed1e8aa"
      },
      "source": [
        "!gcloud auth login\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to the following link in your browser:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?code_challenge=GECwOQj_I77FAhF5iUQyuM1vzY0TYe0d9FafXa3GnB4&prompt=select_account&code_challenge_method=S256&access_type=offline&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&client_id=32555940559.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth\n",
            "\n",
            "\n",
            "Enter verification code: 4/sAHKU_RA47C9iZtUqXzBesNQ8VAz-K9LYrHZq0QDUNPuKxg5DYqJd8Y\n",
            "\u001b[1;33mWARNING:\u001b[0m `gcloud auth login` no longer writes application default credentials.\n",
            "If you need to use ADC, see:\n",
            "  gcloud auth application-default --help\n",
            "\n",
            "You are now logged in as [al@cogneefy.com].\n",
            "Your current project is [None].  You can change this setting by running:\n",
            "  $ gcloud config set project PROJECT_ID\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YigCcV-hSHVH",
        "colab_type": "text"
      },
      "source": [
        "Below is the sample hyperparameter configuration for BERT-base. Change at your own risk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEpSGpUKReKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use this for BERT-base\n",
        "\n",
        "bert_base_config = {\n",
        "  \"attention_probs_dropout_prob\": 0.1, \n",
        "  \"directionality\": \"bidi\", \n",
        "  \"hidden_act\": \"gelu\", \n",
        "  \"hidden_dropout_prob\": 0.1, \n",
        "  \"hidden_size\": 768, \n",
        "  \"initializer_range\": 0.02, \n",
        "  \"intermediate_size\": 3072, \n",
        "  \"max_position_embeddings\": 512, \n",
        "  \"num_attention_heads\": 12, \n",
        "  \"num_hidden_layers\": 12, \n",
        "  \"pooler_fc_size\": 768, \n",
        "  \"pooler_num_attention_heads\": 12, \n",
        "  \"pooler_num_fc_layers\": 3, \n",
        "  \"pooler_size_per_head\": 128, \n",
        "  \"pooler_type\": \"first_token_transform\", \n",
        "  \"type_vocab_size\": 2, \n",
        "  \"vocab_size\": VOC_SIZE\n",
        "}\n",
        "\n",
        "with open(\"{}/bert_config.json\".format(MODEL_DIR), \"w\") as fo:\n",
        "  json.dump(bert_base_config, fo, indent=2)\n",
        "  \n",
        "with open(\"{}/{}\".format(MODEL_DIR, VOC_FNAME), \"w\") as fo:\n",
        "  for token in bert_vocab:\n",
        "    fo.write(token+\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txgrEDugRG48",
        "colab_type": "code",
        "outputId": "a8da2089-30a9-4143-b464-1ca8852a18d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "if BUCKET_NAME:\n",
        "  !gsutil -m cp -r $MODEL_DIR $PRETRAINING_DIR gs://$BUCKET_NAME"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file://pretraining_data/shard_0002.tfrecord [Content-Type=application/octet-stream]...\n",
            "Copying file://bert_model/vocab.txt [Content-Type=text/plain]...\n",
            "Copying file://pretraining_data/shard_0003.tfrecord [Content-Type=application/octet-stream]...\n",
            "Copying file://pretraining_data/shard_0000.tfrecord [Content-Type=application/octet-stream]...\n",
            "Copying file://pretraining_data/shard_0001.tfrecord [Content-Type=application/octet-stream]...\n",
            "Copying file://bert_model/bert_config.json [Content-Type=application/json]...\n",
            "/\n",
            "Operation completed over 6 objects/269.4 MiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DL6xuCAYPrp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gsutil ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gdQEOzhYmSh",
        "colab_type": "text"
      },
      "source": [
        "## Step 7: training the model\n",
        "\n",
        "We are almost ready to begin training our model. If you wish  to continue an interrupted training run, you may skip steps 2-6 and proceed from here.\n",
        "\n",
        "**Make sure that you have set the BUCKET_NAME here as well.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXAuzsJfYrio",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "399abc99-85ab-4342-a039-8b39c05be919",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "BUCKET_NAME = \"evalbert_bucket\" #@param {type:\"string\"}\n",
        "MODEL_DIR = \"bert_model\" #@param {type:\"string\"}\n",
        "PRETRAINING_DIR = \"pretraining_data\" #@param {type:\"string\"}\n",
        "VOC_FNAME = \"vocab.txt\" #@param {type:\"string\"}\n",
        "\n",
        "# Input data pipeline config\n",
        "TRAIN_BATCH_SIZE = 128 #@param {type:\"integer\"}\n",
        "MAX_PREDICTIONS = 20 #@param {type:\"integer\"}\n",
        "MAX_SEQ_LENGTH = 128 #@param {type:\"integer\"}\n",
        "MASKED_LM_PROB = 0.15 #@param\n",
        "\n",
        "# Training procedure config\n",
        "EVAL_BATCH_SIZE = 64\n",
        "LEARNING_RATE = 2e-5\n",
        "TRAIN_STEPS = 1000000 #@param {type:\"integer\"}\n",
        "SAVE_CHECKPOINTS_STEPS = 2500 #@param {type:\"integer\"}\n",
        "NUM_TPU_CORES = 8\n",
        "\n",
        "if BUCKET_NAME:\n",
        "  BUCKET_PATH = \"gs://{}\".format(BUCKET_NAME)\n",
        "else:\n",
        "  BUCKET_PATH = \".\"\n",
        "\n",
        "BERT_GCS_DIR = \"{}/{}\".format(BUCKET_PATH, MODEL_DIR)\n",
        "DATA_GCS_DIR = \"{}/{}\".format(BUCKET_PATH, PRETRAINING_DIR)\n",
        "\n",
        "VOCAB_FILE = os.path.join(BERT_GCS_DIR, VOC_FNAME)\n",
        "CONFIG_FILE = os.path.join(BERT_GCS_DIR, \"bert_config.json\")\n",
        "\n",
        "INIT_CHECKPOINT = tf.train.latest_checkpoint(BERT_GCS_DIR)\n",
        "\n",
        "bert_config = modeling.BertConfig.from_json_file(CONFIG_FILE)\n",
        "input_files = tf.gfile.Glob(os.path.join(DATA_GCS_DIR,'*tfrecord'))\n",
        "\n",
        "log.info(\"Using checkpoint: {}\".format(INIT_CHECKPOINT))\n",
        "log.info(\"Using {} data shards\".format(len(input_files)))"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-10-16 05:34:27,910 :  Using checkpoint: None\n",
            "2019-10-16 05:34:27,916 :  Using 4 data shards\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwwF-WqcZHUG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQTFjITdd53F",
        "colab_type": "text"
      },
      "source": [
        "Prepare the training run configuration, build the estimator and input function, power up the bass cannon."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMahsqUnZ55z",
        "colab_type": "code",
        "outputId": "dc84faaa-6cb6-4a6e-c980-a75fd23cabaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "model_fn = model_fn_builder(\n",
        "      bert_config=bert_config,\n",
        "      init_checkpoint=INIT_CHECKPOINT,\n",
        "      learning_rate=LEARNING_RATE,\n",
        "      num_train_steps=TRAIN_STEPS,\n",
        "      num_warmup_steps=10,\n",
        "      use_tpu=USE_TPU,\n",
        "      use_one_hot_embeddings=True)\n",
        "\n",
        "tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
        "\n",
        "run_config = tf.contrib.tpu.RunConfig(\n",
        "    cluster=tpu_cluster_resolver,\n",
        "    model_dir=BERT_GCS_DIR,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
        "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "        iterations_per_loop=SAVE_CHECKPOINTS_STEPS,\n",
        "        num_shards=NUM_TPU_CORES,\n",
        "        per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))\n",
        "\n",
        "estimator = tf.contrib.tpu.TPUEstimator(\n",
        "    use_tpu=USE_TPU,\n",
        "    model_fn=model_fn,\n",
        "    config=run_config,\n",
        "    train_batch_size=TRAIN_BATCH_SIZE,\n",
        "    eval_batch_size=EVAL_BATCH_SIZE)\n",
        "  \n",
        "train_input_fn = input_fn_builder(\n",
        "        input_files=input_files,\n",
        "        max_seq_length=MAX_SEQ_LENGTH,\n",
        "        max_predictions_per_seq=MAX_PREDICTIONS,\n",
        "        is_training=True)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-10-16 05:34:46,153 :  Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f51c99e9158>) includes params argument, but params are not passed to Estimator.\n",
            "2019-10-16 05:34:46,169 :  Using config: {'_model_dir': 'gs://evalbert_bucket/bert_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 2500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.1.178.146:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f51c99c3ba8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.1.178.146:8470', '_evaluation_master': 'grpc://10.1.178.146:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=2500, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f51c99e6358>}\n",
            "2019-10-16 05:34:46,176 :  _TPUContext: eval_on_tpu True\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNt5ykopeIYB",
        "colab_type": "text"
      },
      "source": [
        "Fire!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrCuEbr6dv8U",
        "colab_type": "code",
        "outputId": "5d774fea-9054-48a5-9fe0-f5c552446e42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "estimator.train(input_fn=train_input_fn, max_steps=TRAIN_STEPS)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-10-16 05:35:03,954 :  Querying Tensorflow master (grpc://10.1.178.146:8470) for TPU system metadata.\n",
            "2019-10-16 05:35:03,977 :  Found TPU system:\n",
            "2019-10-16 05:35:03,979 :  *** Num TPU Cores: 8\n",
            "2019-10-16 05:35:03,983 :  *** Num TPU Workers: 1\n",
            "2019-10-16 05:35:03,985 :  *** Num TPU Cores Per Worker: 8\n",
            "2019-10-16 05:35:03,987 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2880899765638423033)\n",
            "2019-10-16 05:35:03,990 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 8587262342872264045)\n",
            "2019-10-16 05:35:03,991 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 2468141024060117736)\n",
            "2019-10-16 05:35:03,992 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 10848863628410161329)\n",
            "2019-10-16 05:35:03,994 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 237694570509309922)\n",
            "2019-10-16 05:35:03,995 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 15040483007859324903)\n",
            "2019-10-16 05:35:03,996 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 13802014609466302151)\n",
            "2019-10-16 05:35:03,997 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 13551232642661561562)\n",
            "2019-10-16 05:35:03,998 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 5761451890387920589)\n",
            "2019-10-16 05:35:03,999 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 9774526100782111324)\n",
            "2019-10-16 05:35:04,000 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 6146333580018845288)\n",
            "2019-10-16 05:35:04,045 :  From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "2019-10-16 05:35:04,049 :  From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "2019-10-16 05:35:04,087 :  Calling model_fn.\n",
            "2019-10-16 05:35:04,090 :  From /content/bert/run_pretraining.py:337: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "2019-10-16 05:35:04,114 :  From /content/bert/run_pretraining.py:368: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "2019-10-16 05:35:04,118 :  From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "2019-10-16 05:35:04,209 :  From /content/bert/run_pretraining.py:385: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "2019-10-16 05:35:04,211 :  From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "2019-10-16 05:35:04,301 :  From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "2019-10-16 05:35:04,459 :  From /content/bert/run_pretraining.py:400: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "2019-10-16 05:35:04,507 :  Found small feature: next_sentence_labels [16, 1]\n",
            "2019-10-16 05:35:04,513 :  Found small feature: next_sentence_labels [16, 1]\n",
            "2019-10-16 05:35:04,518 :  Found small feature: next_sentence_labels [16, 1]\n",
            "2019-10-16 05:35:04,523 :  Found small feature: next_sentence_labels [16, 1]\n",
            "2019-10-16 05:35:04,528 :  Found small feature: next_sentence_labels [16, 1]\n",
            "2019-10-16 05:35:04,533 :  Found small feature: next_sentence_labels [16, 1]\n",
            "2019-10-16 05:35:04,538 :  Found small feature: next_sentence_labels [16, 1]\n",
            "2019-10-16 05:35:04,543 :  Found small feature: next_sentence_labels [16, 1]\n",
            "2019-10-16 05:35:04,594 :  From /content/bert/run_pretraining.py:117: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "2019-10-16 05:35:04,595 :  *** Features ***\n",
            "2019-10-16 05:35:04,596 :    name = input_ids, shape = (16, 128)\n",
            "2019-10-16 05:35:04,597 :    name = input_mask, shape = (16, 128)\n",
            "2019-10-16 05:35:04,598 :    name = masked_lm_ids, shape = (16, 20)\n",
            "2019-10-16 05:35:04,599 :    name = masked_lm_positions, shape = (16, 20)\n",
            "2019-10-16 05:35:04,600 :    name = masked_lm_weights, shape = (16, 20)\n",
            "2019-10-16 05:35:04,601 :    name = next_sentence_labels, shape = (16, 1)\n",
            "2019-10-16 05:35:04,602 :    name = segment_ids, shape = (16, 128)\n",
            "2019-10-16 05:35:04,603 :  From bert/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "2019-10-16 05:35:04,610 :  From bert/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "2019-10-16 05:35:04,661 :  From bert/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "2019-10-16 05:35:04,732 :  From bert/modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "2019-10-16 05:35:04,760 :  From bert/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "2019-10-16 05:35:04,766 :  From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "2019-10-16 05:35:08,073 :  From /content/bert/run_pretraining.py:150: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "2019-10-16 05:35:08,074 :  **** Trainable Variables ****\n",
            "2019-10-16 05:35:08,076 :    name = bert/embeddings/word_embeddings:0, shape = (32000, 768)\n",
            "2019-10-16 05:35:08,077 :    name = bert/embeddings/token_type_embeddings:0, shape = (2, 768)\n",
            "2019-10-16 05:35:08,078 :    name = bert/embeddings/position_embeddings:0, shape = (512, 768)\n",
            "2019-10-16 05:35:08,079 :    name = bert/embeddings/LayerNorm/beta:0, shape = (768,)\n",
            "2019-10-16 05:35:08,080 :    name = bert/embeddings/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-10-16 05:35:08,080 :    name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,081 :    name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,082 :    name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,083 :    name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,084 :    name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,085 :    name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,086 :    name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,087 :    name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,088 :    name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-10-16 05:35:08,089 :    name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-10-16 05:35:08,090 :    name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "2019-10-16 05:35:08,091 :    name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,)\n",
            "2019-10-16 05:35:08,092 :    name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768)\n",
            "2019-10-16 05:35:08,093 :    name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,094 :    name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-10-16 05:35:08,095 :    name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-10-16 05:35:08,095 :    name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,096 :    name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,097 :    name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,098 :    name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,099 :    name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,100 :    name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,101 :    name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,102 :    name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,103 :    name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-10-16 05:35:08,104 :    name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-10-16 05:35:08,105 :    name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "2019-10-16 05:35:08,106 :    name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,)\n",
            "2019-10-16 05:35:08,106 :    name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768)\n",
            "2019-10-16 05:35:08,107 :    name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,108 :    name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-10-16 05:35:08,109 :    name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-10-16 05:35:08,110 :    name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,111 :    name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,112 :    name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,113 :    name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,114 :    name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,115 :    name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,116 :    name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,117 :    name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,118 :    name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-10-16 05:35:08,119 :    name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-10-16 05:35:08,120 :    name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "2019-10-16 05:35:08,121 :    name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,)\n",
            "2019-10-16 05:35:08,122 :    name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768)\n",
            "2019-10-16 05:35:08,123 :    name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,124 :    name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-10-16 05:35:08,125 :    name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-10-16 05:35:08,126 :    name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,127 :    name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,128 :    name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,129 :    name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,130 :    name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,131 :    name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,132 :    name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,133 :    name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,134 :    name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-10-16 05:35:08,135 :    name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-10-16 05:35:08,136 :    name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "2019-10-16 05:35:08,137 :    name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,)\n",
            "2019-10-16 05:35:08,138 :    name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768)\n",
            "2019-10-16 05:35:08,139 :    name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,140 :    name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-10-16 05:35:08,141 :    name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-10-16 05:35:08,142 :    name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,143 :    name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,144 :    name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,145 :    name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,146 :    name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,147 :    name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,148 :    name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,149 :    name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,150 :    name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-10-16 05:35:08,151 :    name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-10-16 05:35:08,152 :    name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "2019-10-16 05:35:08,153 :    name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,)\n",
            "2019-10-16 05:35:08,154 :    name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768)\n",
            "2019-10-16 05:35:08,155 :    name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,156 :    name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-10-16 05:35:08,157 :    name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-10-16 05:35:08,158 :    name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,159 :    name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,160 :    name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,161 :    name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,162 :    name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,163 :    name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,164 :    name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,165 :    name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,166 :    name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-10-16 05:35:08,166 :    name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-10-16 05:35:08,167 :    name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "2019-10-16 05:35:08,168 :    name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,)\n",
            "2019-10-16 05:35:08,169 :    name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768)\n",
            "2019-10-16 05:35:08,170 :    name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,171 :    name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-10-16 05:35:08,172 :    name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-10-16 05:35:08,173 :    name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,174 :    name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,175 :    name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,176 :    name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,177 :    name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,178 :    name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,179 :    name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,180 :    name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,181 :    name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-10-16 05:35:08,182 :    name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-10-16 05:35:08,183 :    name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "2019-10-16 05:35:08,184 :    name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,)\n",
            "2019-10-16 05:35:08,185 :    name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768)\n",
            "2019-10-16 05:35:08,186 :    name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,187 :    name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-10-16 05:35:08,188 :    name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-10-16 05:35:08,189 :    name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,190 :    name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,191 :    name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,192 :    name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,193 :    name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,194 :    name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,195 :    name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,196 :    name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,197 :    name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-10-16 05:35:08,198 :    name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-10-16 05:35:08,199 :    name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "2019-10-16 05:35:08,200 :    name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,)\n",
            "2019-10-16 05:35:08,201 :    name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768)\n",
            "2019-10-16 05:35:08,202 :    name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,204 :    name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-10-16 05:35:08,205 :    name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-10-16 05:35:08,206 :    name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,207 :    name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,208 :    name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,209 :    name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,210 :    name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,211 :    name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,211 :    name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,212 :    name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,213 :    name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-10-16 05:35:08,214 :    name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-10-16 05:35:08,215 :    name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "2019-10-16 05:35:08,216 :    name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,)\n",
            "2019-10-16 05:35:08,217 :    name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768)\n",
            "2019-10-16 05:35:08,218 :    name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,219 :    name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-10-16 05:35:08,220 :    name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-10-16 05:35:08,221 :    name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,222 :    name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,223 :    name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,224 :    name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,225 :    name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,226 :    name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,227 :    name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,228 :    name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,229 :    name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-10-16 05:35:08,230 :    name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-10-16 05:35:08,232 :    name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "2019-10-16 05:35:08,233 :    name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,)\n",
            "2019-10-16 05:35:08,234 :    name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768)\n",
            "2019-10-16 05:35:08,235 :    name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,236 :    name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-10-16 05:35:08,237 :    name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-10-16 05:35:08,238 :    name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,240 :    name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,241 :    name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,242 :    name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,243 :    name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,244 :    name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,245 :    name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,247 :    name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,248 :    name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-10-16 05:35:08,249 :    name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-10-16 05:35:08,250 :    name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "2019-10-16 05:35:08,251 :    name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,)\n",
            "2019-10-16 05:35:08,252 :    name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768)\n",
            "2019-10-16 05:35:08,253 :    name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,254 :    name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-10-16 05:35:08,255 :    name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-10-16 05:35:08,256 :    name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,257 :    name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,259 :    name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,260 :    name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,261 :    name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,262 :    name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,264 :    name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,265 :    name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,266 :    name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-10-16 05:35:08,267 :    name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-10-16 05:35:08,268 :    name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "2019-10-16 05:35:08,269 :    name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,)\n",
            "2019-10-16 05:35:08,271 :    name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768)\n",
            "2019-10-16 05:35:08,272 :    name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,273 :    name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-10-16 05:35:08,275 :    name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-10-16 05:35:08,277 :    name = bert/pooler/dense/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,278 :    name = bert/pooler/dense/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,279 :    name = cls/predictions/transform/dense/kernel:0, shape = (768, 768)\n",
            "2019-10-16 05:35:08,281 :    name = cls/predictions/transform/dense/bias:0, shape = (768,)\n",
            "2019-10-16 05:35:08,282 :    name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,)\n",
            "2019-10-16 05:35:08,284 :    name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-10-16 05:35:08,285 :    name = cls/predictions/output_bias:0, shape = (32000,)\n",
            "2019-10-16 05:35:08,286 :    name = cls/seq_relationship/output_weights:0, shape = (2, 768)\n",
            "2019-10-16 05:35:08,287 :    name = cls/seq_relationship/output_bias:0, shape = (2,)\n",
            "2019-10-16 05:35:08,289 :  From bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "2019-10-16 05:35:08,294 :  From bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n",
            "2019-10-16 05:35:08,870 :  From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "2019-10-16 05:35:20,540 :  Create CheckpointSaverHook.\n",
            "2019-10-16 05:35:20,883 :  Done calling model_fn.\n",
            "2019-10-16 05:35:23,959 :  TPU job name worker\n",
            "2019-10-16 05:35:25,192 :  Graph was finalized.\n",
            "2019-10-16 05:35:32,074 :  Running local_init_op.\n",
            "2019-10-16 05:35:32,531 :  Done running local_init_op.\n",
            "2019-10-16 05:35:41,672 :  Saving checkpoints for 0 into gs://evalbert_bucket/bert_model/model.ckpt.\n",
            "2019-10-16 05:36:10,301 :  From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:751: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "2019-10-16 05:36:11,339 :  Initialized dataset iterators in 0 seconds\n",
            "2019-10-16 05:36:11,341 :  Installing graceful shutdown hook.\n",
            "2019-10-16 05:36:11,349 :  Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
            "2019-10-16 05:36:11,356 :  Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "2019-10-16 05:36:11,363 :  Init TPU system\n",
            "2019-10-16 05:36:18,870 :  Initialized TPU in 7 seconds\n",
            "2019-10-16 05:36:18,872 :  Starting infeed thread controller.\n",
            "2019-10-16 05:36:18,890 :  Starting outfeed thread controller.\n",
            "2019-10-16 05:36:19,467 :  Enqueue next (2500) batch(es) of data to infeed.\n",
            "2019-10-16 05:36:19,468 :  Dequeue next (2500) batch(es) of data from outfeed.\n",
            "2019-10-16 05:36:54,042 :  Outfeed finished for iteration (0, 0)\n",
            "2019-10-16 05:37:54,108 :  Outfeed finished for iteration (0, 552)\n",
            "2019-10-16 05:38:54,177 :  Outfeed finished for iteration (0, 1104)\n",
            "2019-10-16 05:39:54,246 :  Outfeed finished for iteration (0, 1656)\n",
            "2019-10-16 05:40:54,315 :  Outfeed finished for iteration (0, 2208)\n",
            "2019-10-16 05:41:26,798 :  Saving checkpoints for 2500 into gs://evalbert_bucket/bert_model/model.ckpt.\n",
            "2019-10-16 05:41:57,418 :  loss = 6.566591, step = 2500\n",
            "2019-10-16 05:41:57,423 :  Enqueue next (2500) batch(es) of data to infeed.\n",
            "2019-10-16 05:41:57,425 :  Dequeue next (2500) batch(es) of data from outfeed.\n",
            "2019-10-16 05:42:02,693 :  Outfeed finished for iteration (1, 0)\n",
            "2019-10-16 05:43:02,748 :  Outfeed finished for iteration (1, 552)\n",
            "2019-10-16 05:44:02,807 :  Outfeed finished for iteration (1, 1104)\n",
            "2019-10-16 05:45:02,865 :  Outfeed finished for iteration (1, 1656)\n",
            "2019-10-16 05:46:02,924 :  Outfeed finished for iteration (1, 2208)\n",
            "2019-10-16 05:46:35,330 :  Saving checkpoints for 5000 into gs://evalbert_bucket/bert_model/model.ckpt.\n",
            "2019-10-16 05:47:11,347 :  loss = 6.222795, step = 5000 (313.929 sec)\n",
            "2019-10-16 05:47:11,351 :  global_step/sec: 7.96361\n",
            "2019-10-16 05:47:11,355 :  examples/sec: 1019.34\n",
            "2019-10-16 05:47:11,359 :  Enqueue next (2500) batch(es) of data to infeed.\n",
            "2019-10-16 05:47:11,360 :  Dequeue next (2500) batch(es) of data from outfeed.\n",
            "2019-10-16 05:47:12,650 :  Outfeed finished for iteration (2, 0)\n",
            "2019-10-16 05:48:12,729 :  Outfeed finished for iteration (2, 552)\n",
            "2019-10-16 05:49:12,812 :  Outfeed finished for iteration (2, 1104)\n",
            "2019-10-16 05:50:12,894 :  Outfeed finished for iteration (2, 1656)\n",
            "2019-10-16 05:51:12,976 :  Outfeed finished for iteration (2, 2208)\n",
            "2019-10-16 05:51:45,405 :  Saving checkpoints for 7500 into gs://evalbert_bucket/bert_model/model.ckpt.\n",
            "2019-10-16 05:52:19,567 :  loss = 5.7890053, step = 7500 (308.220 sec)\n",
            "2019-10-16 05:52:19,573 :  global_step/sec: 8.11102\n",
            "2019-10-16 05:52:19,577 :  examples/sec: 1038.21\n",
            "2019-10-16 05:52:19,582 :  Enqueue next (2500) batch(es) of data to infeed.\n",
            "2019-10-16 05:52:19,584 :  Dequeue next (2500) batch(es) of data from outfeed.\n",
            "2019-10-16 05:52:20,836 :  Outfeed finished for iteration (3, 0)\n",
            "2019-10-16 05:53:20,905 :  Outfeed finished for iteration (3, 552)\n",
            "2019-10-16 05:54:20,976 :  Outfeed finished for iteration (3, 1104)\n",
            "2019-10-16 05:55:21,046 :  Outfeed finished for iteration (3, 1656)\n",
            "2019-10-16 05:56:21,117 :  Outfeed finished for iteration (3, 2208)\n",
            "2019-10-16 05:56:53,555 :  Saving checkpoints for 10000 into gs://evalbert_bucket/bert_model/model.ckpt.\n",
            "2019-10-16 05:57:25,113 :  loss = 5.5800376, step = 10000 (305.546 sec)\n",
            "2019-10-16 05:57:25,116 :  global_step/sec: 8.18216\n",
            "2019-10-16 05:57:25,121 :  examples/sec: 1047.32\n",
            "2019-10-16 05:57:25,124 :  Enqueue next (2500) batch(es) of data to infeed.\n",
            "2019-10-16 05:57:25,126 :  Dequeue next (2500) batch(es) of data from outfeed.\n",
            "2019-10-16 05:57:26,398 :  Outfeed finished for iteration (4, 0)\n",
            "2019-10-16 05:58:26,474 :  Outfeed finished for iteration (4, 552)\n",
            "2019-10-16 05:59:26,550 :  Outfeed finished for iteration (4, 1104)\n",
            "2019-10-16 06:00:26,628 :  Outfeed finished for iteration (4, 1656)\n",
            "2019-10-16 06:01:26,705 :  Outfeed finished for iteration (4, 2208)\n",
            "2019-10-16 06:01:59,095 :  Saving checkpoints for 12500 into gs://evalbert_bucket/bert_model/model.ckpt.\n",
            "2019-10-16 06:02:27,038 :  From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "2019-10-16 06:02:30,929 :  loss = 5.5597734, step = 12500 (305.816 sec)\n",
            "2019-10-16 06:02:30,937 :  global_step/sec: 8.17471\n",
            "2019-10-16 06:02:30,939 :  examples/sec: 1046.36\n",
            "2019-10-16 06:02:30,943 :  Enqueue next (2500) batch(es) of data to infeed.\n",
            "2019-10-16 06:02:30,944 :  Dequeue next (2500) batch(es) of data from outfeed.\n",
            "2019-10-16 06:02:32,272 :  Outfeed finished for iteration (5, 0)\n",
            "2019-10-16 06:03:32,334 :  Outfeed finished for iteration (5, 552)\n",
            "2019-10-16 06:04:32,397 :  Outfeed finished for iteration (5, 1104)\n",
            "2019-10-16 06:05:32,460 :  Outfeed finished for iteration (5, 1656)\n",
            "2019-10-16 06:06:32,523 :  Outfeed finished for iteration (5, 2208)\n",
            "2019-10-16 06:07:04,899 :  Saving checkpoints for 15000 into gs://evalbert_bucket/bert_model/model.ckpt.\n",
            "2019-10-16 06:07:39,593 :  loss = 5.2509904, step = 15000 (308.664 sec)\n",
            "2019-10-16 06:07:39,595 :  global_step/sec: 8.09957\n",
            "2019-10-16 06:07:39,600 :  examples/sec: 1036.74\n",
            "2019-10-16 06:07:39,603 :  Enqueue next (2500) batch(es) of data to infeed.\n",
            "2019-10-16 06:07:39,605 :  Dequeue next (2500) batch(es) of data from outfeed.\n",
            "2019-10-16 06:07:40,882 :  Outfeed finished for iteration (6, 0)\n",
            "2019-10-16 06:08:40,962 :  Outfeed finished for iteration (6, 552)\n",
            "2019-10-16 06:09:41,042 :  Outfeed finished for iteration (6, 1104)\n",
            "2019-10-16 06:10:41,121 :  Outfeed finished for iteration (6, 1656)\n",
            "2019-10-16 06:11:41,202 :  Outfeed finished for iteration (6, 2208)\n",
            "2019-10-16 06:12:13,672 :  Saving checkpoints for 17500 into gs://evalbert_bucket/bert_model/model.ckpt.\n",
            "2019-10-16 06:12:49,169 :  loss = 4.512749, step = 17500 (309.577 sec)\n",
            "2019-10-16 06:12:49,174 :  global_step/sec: 8.0755\n",
            "2019-10-16 06:12:49,178 :  examples/sec: 1033.66\n",
            "2019-10-16 06:12:49,182 :  Enqueue next (2500) batch(es) of data to infeed.\n",
            "2019-10-16 06:12:49,184 :  Dequeue next (2500) batch(es) of data from outfeed.\n",
            "2019-10-16 06:12:50,445 :  Outfeed finished for iteration (7, 0)\n",
            "2019-10-16 06:13:50,536 :  Outfeed finished for iteration (7, 552)\n",
            "2019-10-16 06:14:50,626 :  Outfeed finished for iteration (7, 1104)\n",
            "2019-10-16 06:15:50,717 :  Outfeed finished for iteration (7, 1656)\n",
            "2019-10-16 06:16:50,807 :  Outfeed finished for iteration (7, 2208)\n",
            "2019-10-16 06:17:23,263 :  Saving checkpoints for 20000 into gs://evalbert_bucket/bert_model/model.ckpt.\n",
            "2019-10-16 06:18:01,758 :  loss = 4.152376, step = 20000 (312.589 sec)\n",
            "2019-10-16 06:18:01,762 :  global_step/sec: 7.99774\n",
            "2019-10-16 06:18:01,766 :  examples/sec: 1023.71\n",
            "2019-10-16 06:18:01,771 :  Enqueue next (2500) batch(es) of data to infeed.\n",
            "2019-10-16 06:18:01,773 :  Dequeue next (2500) batch(es) of data from outfeed.\n",
            "2019-10-16 06:18:03,079 :  Outfeed finished for iteration (8, 0)\n",
            "2019-10-16 06:19:03,147 :  Outfeed finished for iteration (8, 552)\n",
            "2019-10-16 06:20:03,217 :  Outfeed finished for iteration (8, 1104)\n",
            "2019-10-16 06:21:03,285 :  Outfeed finished for iteration (8, 1656)\n",
            "2019-10-16 06:22:03,355 :  Outfeed finished for iteration (8, 2208)\n",
            "2019-10-16 06:22:35,790 :  Saving checkpoints for 22500 into gs://evalbert_bucket/bert_model/model.ckpt.\n",
            "2019-10-16 06:23:11,965 :  loss = 4.080105, step = 22500 (310.208 sec)\n",
            "2019-10-16 06:23:11,968 :  global_step/sec: 8.05915\n",
            "2019-10-16 06:23:11,971 :  examples/sec: 1031.57\n",
            "2019-10-16 06:23:11,975 :  Enqueue next (2500) batch(es) of data to infeed.\n",
            "2019-10-16 06:23:11,978 :  Dequeue next (2500) batch(es) of data from outfeed.\n",
            "2019-10-16 06:23:13,260 :  Outfeed finished for iteration (9, 0)\n",
            "2019-10-16 06:24:13,321 :  Outfeed finished for iteration (9, 552)\n",
            "2019-10-16 06:25:13,382 :  Outfeed finished for iteration (9, 1104)\n",
            "2019-10-16 06:26:13,444 :  Outfeed finished for iteration (9, 1656)\n",
            "2019-10-16 06:27:13,505 :  Outfeed finished for iteration (9, 2208)\n",
            "2019-10-16 06:27:45,933 :  Saving checkpoints for 25000 into gs://evalbert_bucket/bert_model/model.ckpt.\n",
            "2019-10-16 06:28:17,618 :  loss = 3.5859814, step = 25000 (305.653 sec)\n",
            "2019-10-16 06:28:17,621 :  global_step/sec: 8.17922\n",
            "2019-10-16 06:28:17,622 :  examples/sec: 1046.94\n",
            "2019-10-16 06:28:17,631 :  Enqueue next (2500) batch(es) of data to infeed.\n",
            "2019-10-16 06:28:17,634 :  Dequeue next (2500) batch(es) of data from outfeed.\n",
            "2019-10-16 06:28:18,958 :  Outfeed finished for iteration (10, 0)\n",
            "2019-10-16 06:29:19,023 :  Outfeed finished for iteration (10, 552)\n",
            "2019-10-16 06:30:19,087 :  Outfeed finished for iteration (10, 1104)\n",
            "2019-10-16 06:31:19,153 :  Outfeed finished for iteration (10, 1656)\n",
            "2019-10-16 06:32:19,217 :  Outfeed finished for iteration (10, 2208)\n",
            "2019-10-16 06:32:51,601 :  Saving checkpoints for 27500 into gs://evalbert_bucket/bert_model/model.ckpt.\n",
            "2019-10-16 06:33:33,652 :  loss = 3.5233562, step = 27500 (316.034 sec)\n",
            "2019-10-16 06:33:33,656 :  global_step/sec: 7.9105\n",
            "2019-10-16 06:33:33,660 :  examples/sec: 1012.54\n",
            "2019-10-16 06:33:33,664 :  Enqueue next (2500) batch(es) of data to infeed.\n",
            "2019-10-16 06:33:33,665 :  Dequeue next (2500) batch(es) of data from outfeed.\n",
            "2019-10-16 06:33:34,986 :  Outfeed finished for iteration (11, 0)\n",
            "2019-10-16 06:34:35,049 :  Outfeed finished for iteration (11, 552)\n",
            "2019-10-16 06:35:35,112 :  Outfeed finished for iteration (11, 1104)\n",
            "2019-10-16 06:36:35,175 :  Outfeed finished for iteration (11, 1656)\n",
            "2019-10-16 06:37:35,237 :  Outfeed finished for iteration (11, 2208)\n",
            "2019-10-16 06:38:07,661 :  Saving checkpoints for 30000 into gs://evalbert_bucket/bert_model/model.ckpt.\n",
            "2019-10-16 06:38:38,396 :  loss = 3.1085906, step = 30000 (304.744 sec)\n",
            "2019-10-16 06:38:38,399 :  global_step/sec: 8.20365\n",
            "2019-10-16 06:38:38,402 :  examples/sec: 1050.07\n",
            "2019-10-16 06:38:38,405 :  Enqueue next (2500) batch(es) of data to infeed.\n",
            "2019-10-16 06:38:38,407 :  Dequeue next (2500) batch(es) of data from outfeed.\n",
            "2019-10-16 06:38:39,724 :  Outfeed finished for iteration (12, 0)\n",
            "2019-10-16 06:39:39,790 :  Outfeed finished for iteration (12, 552)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_OeXod-fHMT",
        "colab_type": "text"
      },
      "source": [
        "Training the model with the default parameters for 1 million steps will take ~53 hours. \n",
        "\n",
        "In case the kernel is restarted, you may always continue training from the latest checkpoint. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77ZIAAATfzdF",
        "colab_type": "text"
      },
      "source": [
        "This concludes the guide to pre-training BERT from scratch on a cloud TPU. However, the really fun stuff is still  to come, so stay tuned.\n",
        "\n",
        "Keep learning!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiFH_9Lbze5f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gsutil cp gs://hermes_assets/russian_uncased_L-12_H-768_A-12.zip gs://bert_resourses/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PP7_2pKWzfiZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}